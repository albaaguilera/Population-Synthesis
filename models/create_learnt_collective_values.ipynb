{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mique\\AppData\\Local\\Temp\\ipykernel_15944\\3133058008.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cleaning:  3054\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "valors_socials_cat = pd.read_csv('data/values/collective_values.csv', encoding='windows-1252', delimiter=';')\n",
    "\n",
    "# variables socio-demogràfiques i laborals\n",
    "# eliminat: 'DISTRICTE'\n",
    "columns_to_keep = ['SEXE', 'EDAT', 'CIUTADANIA', 'ESTUDIS_1_6', 'ESTAT_CIVIL_2',\n",
    "                   'CLASSE_SOCIAL_SUBJECTIVA_1_7', 'SIT_LAB', 'FILLS', 'PERSONES_LLAR']\n",
    "\n",
    "# Inglehart’s\n",
    "columns_to_keep.extend(['POSTMAT_1A', 'POSTMAT_1B','POSTMAT_2A','POSTMAT_2B'])\n",
    "\n",
    "# Schwartz’s\n",
    "columns_to_keep.extend(['VHB_A_AUTODIRECCIO1', 'VHB_B_PODER1','VHB_C_UNIVERSALISME1',\n",
    "                        'VHB_D_ASSOLIMENT1', 'VHB_E_SEGURETAT1', 'VHB_F_ESTIMULANT1',\n",
    "                        'VHB_G_CONFORMITAT1', 'VHB_H_UNIVERSALISME2',\n",
    "                        'VHB_I_TRADICIO1', 'VHB_J_HEDONISME1','VHB_K_AUTODIRECCIO2',\n",
    "                        'VHB_L_BENEVOLENCIA1', 'VHB_M_ASSOLIMENT2', 'VHB_N_SEGURETAT2',\n",
    "                        'VHB_O_ESTIMULANT2', 'VHB_P_CONFORMITAT3','VHB_Q_PODER2',\n",
    "                        'VHB_R_BENEVOLENCIA2', 'VHB_S_UNIVERSALISME3', 'VHB_T_TRADICIO2', 'VHB_U_HEDONISME2'])\n",
    "\n",
    "# Altres columnes que m'han semblat interessants\n",
    "columns_to_keep.extend(['LLOC_NAIX', 'LLENGUA_IDENTIFICACIO','IMP_FAMILIA','IMP_AMICS',\n",
    "                        'IMP_LLEURE', 'IMP_POLITICA','IMP_TREBALL','IMP_RELIGIO','SATIS_VIDA',\n",
    "                        'CONFI_SOCIAL_WVS_1', 'SALUT','FELICITAT','ACTITUD_ECONOMIA','ACTITUD_IMMIGRACIO',\n",
    "                        'ACTITUD_MEDIAMBIENT', 'DESIGUALTATS_GENERE','ECON_MERITOCRACIA','MEDIAMBIENT_CREIXEMENT',\n",
    "                        'IMMIGRACIO_CULTURA', 'CONFI_POLICIA','CONFI_POLITICS','IDEOL_0_10','PERSONA_RELIGIOSA',\n",
    "                        'DEPENDENCIA_ECO_PARES', 'INGRESSOS_1_15','INFO_POL_TV_FREQ','FREQ_CONSUM_INTERNET'])\n",
    "\n",
    "valors_socials_cat = valors_socials_cat.loc[:, columns_to_keep]\n",
    "\n",
    "# rename columns\n",
    "new_column_names = {'DISTRICTE': 'D', 'SEXE': 'G', 'EDAT': 'DA', 'CIUTADANIA': 'N', 'ESTUDIS_1_6': 'E',\n",
    "                    'ESTAT_CIVIL_2': 'S', 'CLASSE_SOCIAL_SUBJECTIVA_1_7': 'C', 'SIT_LAB': 'U','FILLS': 'Ch',\n",
    "                    'PERSONES_LLAR': 'HR'}\n",
    "valors_socials_cat.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Neteja dades\n",
    "values_to_remove = ['Valor perdut per error tècnic', 'Valor perdut per omissió de resposta', \"Valor perdut per mode d'administració de l'enquesta\"]\n",
    "valors_socials_cat.replace(values_to_remove, np.nan, inplace=True)\n",
    "valors_socials_cat.dropna(inplace=True)\n",
    "print('Rows after cleaning: ', valors_socials_cat.shape[0])\n",
    "\n",
    "def discretize_age(x):\n",
    "    x = int(x)\n",
    "    if x < 25:\n",
    "        return 1\n",
    "    elif x < 35:\n",
    "        return 2\n",
    "    elif x < 45:\n",
    "        return 3\n",
    "    elif x < 55:\n",
    "        return 4\n",
    "    elif x < 65:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "valors_socials_cat['DA'] = valors_socials_cat['DA'].apply(discretize_age)\n",
    "\n",
    "def discretize_llar(x):\n",
    "    x = int(x)\n",
    "    if x < 2:\n",
    "        return 1\n",
    "    elif x == 2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "valors_socials_cat['HR'] = valors_socials_cat['HR'].apply(discretize_llar)\n",
    "\n",
    "def discretize_fills(x):\n",
    "    x = int(x)\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "valors_socials_cat['Ch'] = valors_socials_cat['Ch'].apply(discretize_fills)\n",
    "\n",
    "def discretize_inglehart_1(x):\n",
    "    if x == 'Combatre la pujada dels preus' or x == 'Mantenir l’ordre en el país':\n",
    "        return 1 # materialistes\n",
    "    elif x == 'Protegir la llibertat d’expressió' or x == 'Augmentar la participació dels ciutadans en les decisions importants del govern':\n",
    "        return 2 # post materialistes\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def discretize_inglehart_2(x):\n",
    "    if x == 'Una economia estable' or x == 'La lluita contra la delinqüència':\n",
    "        return 1 # materialistes\n",
    "    elif x == 'Avançar cap a una societat menys impersonal i més humana' or x == 'Avançar cap a una societat on les idees siguin més important que els diners':\n",
    "        return 2 # post materialistes\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "valors_socials_cat['POSTMAT_1A'] = valors_socials_cat['POSTMAT_1A'].apply(discretize_inglehart_1)\n",
    "valors_socials_cat['POSTMAT_1B'] = valors_socials_cat['POSTMAT_1B'].apply(discretize_inglehart_1)\n",
    "valors_socials_cat['POSTMAT_2A'] = valors_socials_cat['POSTMAT_2A'].apply(discretize_inglehart_2)\n",
    "valors_socials_cat['POSTMAT_2B'] = valors_socials_cat['POSTMAT_2B'].apply(discretize_inglehart_2)\n",
    "\n",
    "# Encode values into a single variable\n",
    "valors_socials_cat['Inglehart_index'] = (\n",
    "    (valors_socials_cat['POSTMAT_1A'] - 1)*2 + # give more importance to the first selection\n",
    "    (valors_socials_cat['POSTMAT_1B'] - 1) +\n",
    "    (valors_socials_cat['POSTMAT_2A'] - 1)*2 +\n",
    "    (valors_socials_cat['POSTMAT_2B'] - 1)\n",
    ") # 0 -> full materialist, 6 -> full post-materialist\n",
    "\n",
    "valors_socials_cat.drop(columns=['POSTMAT_1A', 'POSTMAT_1B', 'POSTMAT_2A', 'POSTMAT_2B'], inplace=True)\n",
    "\n",
    "def discretize_ideo(x):\n",
    "    x = int(x[0:2])\n",
    "    if x < 4:\n",
    "        return 1 # esquerra\n",
    "    elif x < 7:\n",
    "        return 2 # centre\n",
    "    else:\n",
    "        return 3 #dretes\n",
    "\n",
    "valors_socials_cat['IDEOL_0_10'] = valors_socials_cat['IDEOL_0_10'].apply(discretize_ideo)\n",
    "\n",
    "def discretize_des_gen(x):\n",
    "    x = int(x[0:2])\n",
    "    if x < 4:\n",
    "        return 1 # perjudici homes\n",
    "    elif x < 7:\n",
    "        return 2 # centre\n",
    "    else:\n",
    "        return 3 # perjudici dones\n",
    "\n",
    "valors_socials_cat['DESIGUALTATS_GENERE'] = valors_socials_cat['DESIGUALTATS_GENERE'].apply(discretize_des_gen)\n",
    "\n",
    "def discretize_medi(x):\n",
    "    if x == 'D’acord' or x=='Molt d’acord':\n",
    "        return 1 # prioritat economia\n",
    "    elif x == 'Ni d’acord ni en desacord':\n",
    "        return 2 # centre\n",
    "    elif x == 'En desacord' or x=='Molt en desacord':\n",
    "        return 3 # prioritat medi ambient\n",
    "\n",
    "valors_socials_cat['ACTITUD_MEDIAMBIENT'] = valors_socials_cat['ACTITUD_MEDIAMBIENT'].apply(discretize_medi)\n",
    "\n",
    "def discretize_immi(x):\n",
    "    if x == 'D’acord' or x=='Molt d’acord':\n",
    "        return 1 # immigració dolenta\n",
    "    elif x == 'Ni d’acord ni en desacord':\n",
    "        return 2 # centre\n",
    "    elif x == 'En desacord' or x=='Molt en desacord':\n",
    "        return 3\n",
    "\n",
    "valors_socials_cat['ACTITUD_IMMIGRACIO'] = valors_socials_cat['ACTITUD_IMMIGRACIO'].apply(discretize_immi)\n",
    "\n",
    "def discretize_poli(x):\n",
    "    x = int(x[0:2])\n",
    "    if x < 4:\n",
    "        return 1 # no confia\n",
    "    elif x < 7:\n",
    "        return 2 # centre\n",
    "    else:\n",
    "        return 3 # confia\n",
    "\n",
    "valors_socials_cat['CONFI_POLICIA'] = valors_socials_cat['CONFI_POLICIA'].apply(discretize_poli)\n",
    "\n",
    "\n",
    "def discretize_VHB(x):\n",
    "    if x == 'No s’assembla a mi' or x=='No s’assembla gens a mi':\n",
    "        return 1\n",
    "    elif x == 'S’assembla poc a mi' or x=='S’assembla una mica a mi':\n",
    "        return 2\n",
    "    elif x == 'S’assembla a mi' or x=='S’assembla molt a mi':\n",
    "        return 3\n",
    "\n",
    "valors_socials_cat['VHB_A_AUTODIRECCIO1'] = valors_socials_cat['VHB_A_AUTODIRECCIO1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_B_PODER1'] = valors_socials_cat['VHB_B_PODER1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_C_UNIVERSALISME1'] = valors_socials_cat['VHB_C_UNIVERSALISME1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_D_ASSOLIMENT1'] = valors_socials_cat['VHB_D_ASSOLIMENT1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_E_SEGURETAT1'] = valors_socials_cat['VHB_E_SEGURETAT1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_F_ESTIMULANT1'] = valors_socials_cat['VHB_F_ESTIMULANT1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_G_CONFORMITAT1'] = valors_socials_cat['VHB_G_CONFORMITAT1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_H_UNIVERSALISME2'] = valors_socials_cat['VHB_H_UNIVERSALISME2'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_I_TRADICIO1'] = valors_socials_cat['VHB_I_TRADICIO1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_J_HEDONISME1'] = valors_socials_cat['VHB_J_HEDONISME1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_K_AUTODIRECCIO2'] = valors_socials_cat['VHB_K_AUTODIRECCIO2'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_L_BENEVOLENCIA1'] = valors_socials_cat['VHB_L_BENEVOLENCIA1'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_M_ASSOLIMENT2'] = valors_socials_cat['VHB_M_ASSOLIMENT2'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_N_SEGURETAT2'] = valors_socials_cat['VHB_N_SEGURETAT2'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_O_ESTIMULANT2'] = valors_socials_cat['VHB_O_ESTIMULANT2'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_P_CONFORMITAT3'] = valors_socials_cat['VHB_P_CONFORMITAT3'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_Q_PODER2'] = valors_socials_cat['VHB_Q_PODER2'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_R_BENEVOLENCIA2'] = valors_socials_cat['VHB_R_BENEVOLENCIA2'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_S_UNIVERSALISME3'] = valors_socials_cat['VHB_S_UNIVERSALISME3'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_T_TRADICIO2'] = valors_socials_cat['VHB_T_TRADICIO2'].apply(discretize_VHB)\n",
    "valors_socials_cat['VHB_U_HEDONISME2'] = valors_socials_cat['VHB_U_HEDONISME2'].apply(discretize_VHB)\n",
    "\n",
    "# Encode values into a single variable\n",
    "valors_socials_cat['Universalism'] = ((valors_socials_cat['VHB_C_UNIVERSALISME1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_H_UNIVERSALISME2'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_S_UNIVERSALISME3'] - 1))\n",
    "\n",
    "valors_socials_cat['Stimulation'] = ((valors_socials_cat['VHB_F_ESTIMULANT1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_O_ESTIMULANT2'] - 1))\n",
    "\n",
    "valors_socials_cat['Hedonism'] = ((valors_socials_cat['VHB_J_HEDONISME1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_U_HEDONISME2'] - 1))\n",
    "\n",
    "valors_socials_cat['Self-Direction'] = ((valors_socials_cat['VHB_A_AUTODIRECCIO1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_K_AUTODIRECCIO2'] - 1))\n",
    "\n",
    "valors_socials_cat['Achievement'] = ((valors_socials_cat['VHB_D_ASSOLIMENT1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_M_ASSOLIMENT2'] - 1))\n",
    "\n",
    "valors_socials_cat['Power'] = ((valors_socials_cat['VHB_B_PODER1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_Q_PODER2'] - 1))\n",
    "\n",
    "valors_socials_cat['Security'] = ((valors_socials_cat['VHB_E_SEGURETAT1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_N_SEGURETAT2'] - 1))\n",
    "\n",
    "valors_socials_cat['Conformity'] = ((valors_socials_cat['VHB_F_ESTIMULANT1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_O_ESTIMULANT2'] - 1))\n",
    "\n",
    "valors_socials_cat['Tradition'] = ((valors_socials_cat['VHB_I_TRADICIO1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_T_TRADICIO2'] - 1))\n",
    "\n",
    "valors_socials_cat['Benevolence'] = ((valors_socials_cat['VHB_L_BENEVOLENCIA1'] - 1) +\n",
    "                                     (valors_socials_cat['VHB_R_BENEVOLENCIA2'] - 1))\n",
    "\n",
    "\n",
    "valors_socials_cat.drop(columns=['VHB_A_AUTODIRECCIO1', 'VHB_B_PODER1','VHB_C_UNIVERSALISME1',\n",
    "                                'VHB_D_ASSOLIMENT1', 'VHB_E_SEGURETAT1', 'VHB_F_ESTIMULANT1',\n",
    "                                'VHB_G_CONFORMITAT1', 'VHB_H_UNIVERSALISME2',\n",
    "                                'VHB_I_TRADICIO1', 'VHB_J_HEDONISME1','VHB_K_AUTODIRECCIO2',\n",
    "                                'VHB_L_BENEVOLENCIA1', 'VHB_M_ASSOLIMENT2', 'VHB_N_SEGURETAT2',\n",
    "                                'VHB_O_ESTIMULANT2', 'VHB_P_CONFORMITAT3','VHB_Q_PODER2',\n",
    "                                'VHB_R_BENEVOLENCIA2', 'VHB_S_UNIVERSALISME3', 'VHB_T_TRADICIO2', 'VHB_U_HEDONISME2'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.estimators import BicScore, MmhcEstimator, HillClimbSearch, ExpectationMaximization\n",
    "from pgmpy.models import BayesianNetwork\n",
    "\n",
    "est = HillClimbSearch(valors_socials_cat)\n",
    "# Estimate the structure\n",
    "VS_cat_structure_model = est.estimate(scoring_method=BicScore(valors_socials_cat))\n",
    "\n",
    "VS_cat_structure_model = BayesianNetwork(VS_cat_structure_model.edges())\n",
    "# We need to manually add independent variables, as they do no appear in the DAG\n",
    "VS_cat_structure_model.fit(valors_socials_cat, estimator=ExpectationMaximization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benevolence -> ['Universalism']\n",
      "DESIGUALTATS_GENERE -> ['G']\n",
      "PERSONA_RELIGIOSA -> ['Tradition']\n",
      "CONFI_SOCIAL_WVS_1 -> ['SATIS_VIDA', 'ECON_MERITOCRACIA', 'C']\n",
      "N -> ['LLOC_NAIX']\n",
      "HR -> ['DA', 'S']\n",
      "IMP_POLITICA -> ['INFO_POL_TV_FREQ', 'ACTITUD_ECONOMIA']\n",
      "DEPENDENCIA_ECO_PARES -> ['INGRESSOS_1_15', 'LLOC_NAIX', 'G']\n",
      "IDEOL_0_10 -> ['DESIGUALTATS_GENERE', 'IMP_RELIGIO']\n",
      "IMP_AMICS -> ['Benevolence', 'IMP_FAMILIA']\n",
      "IMP_LLEURE -> ['IMP_AMICS']\n",
      "ACTITUD_ECONOMIA -> ['ACTITUD_IMMIGRACIO']\n",
      "Stimulation -> ['Conformity']\n",
      "Conformity -> ['Hedonism']\n",
      "LLOC_NAIX -> ['LLENGUA_IDENTIFICACIO']\n",
      "DA -> ['DEPENDENCIA_ECO_PARES', 'E', 'IMP_TREBALL', 'U']\n",
      "Power -> ['Achievement']\n",
      "ACTITUD_MEDIAMBIENT -> ['MEDIAMBIENT_CREIXEMENT']\n",
      "CONFI_POLITICS -> ['CONFI_POLICIA', 'IMP_POLITICA']\n",
      "ACTITUD_IMMIGRACIO -> ['IMMIGRACIO_CULTURA', 'Inglehart_index', 'ACTITUD_MEDIAMBIENT', 'Security', 'CONFI_SOCIAL_WVS_1', 'DESIGUALTATS_GENERE']\n",
      "Self-Direction -> ['Stimulation']\n",
      "Hedonism -> ['Ch', 'Power', 'IMP_LLEURE']\n",
      "SATIS_VIDA -> ['FELICITAT']\n",
      "IMP_RELIGIO -> ['PERSONA_RELIGIOSA', 'N']\n",
      "Inglehart_index -> ['IDEOL_0_10']\n",
      "CONFI_POLICIA -> ['LLENGUA_IDENTIFICACIO']\n",
      "FELICITAT -> ['SALUT']\n",
      "Ch -> ['S', 'DA', 'HR', 'IMP_FAMILIA', 'CONFI_SOCIAL_WVS_1']\n"
     ]
    }
   ],
   "source": [
    "# create a dict to visualize the dependendies\n",
    "depend_dict = {}\n",
    "for connection in VS_cat_structure_model.edges():\n",
    "    \n",
    "    if not connection[0] in depend_dict.keys():\n",
    "        depend_dict[connection[0]] = [connection[1]]\n",
    "    else:\n",
    "        depend_dict[connection[0]].append(connection[1])\n",
    "\n",
    "nodes_in_DAG = set()\n",
    "for edge in VS_cat_structure_model.edges():\n",
    "    nodes_in_DAG.add(edge[0])\n",
    "    nodes_in_DAG.add(edge[1])\n",
    "\n",
    "# nodes_in_DAG imposes an ordering of variables for the plot\n",
    "for feature in nodes_in_DAG:\n",
    "    for key in depend_dict.keys():\n",
    "        if key == feature:\n",
    "            print(str(key)+\" -> \"+str(depend_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:03<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import ExpectationMaximization\n",
    "\n",
    "VS_model = BayesianNetwork(VS_cat_structure_model.edges())\n",
    "VS_model.fit(valors_socials_cat, estimator=ExpectationMaximization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.readwrite import BIFWriter\n",
    "\n",
    "writer = BIFWriter(VS_model)\n",
    "writer.write_bif('models/learned_model_cat_values.pgmx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Node POSTMAT_1A not in not in graph",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m materialista \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTMAT_1A\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTMAT_1B\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTMAT_2A\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTMAT_2B\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n\u001b[0;32m      6\u001b[0m post_materialista \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTMAT_1A\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTMAT_1B\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTMAT_2A\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTMAT_2B\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[1;32m----> 9\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[43minfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mACTITUD_IMMIGRACIO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaterialista\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaterialista:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, q)\n\u001b[0;32m     11\u001b[0m q \u001b[38;5;241m=\u001b[39m infer\u001b[38;5;241m.\u001b[39mquery(variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACTITUD_IMMIGRACIO\u001b[39m\u001b[38;5;124m\"\u001b[39m], evidence\u001b[38;5;241m=\u001b[39mpost_materialista)\n",
      "File \u001b[1;32mc:\\Users\\mique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pgmpy\\inference\\ExactInference.py:318\u001b[0m, in \u001b[0;36mVariableElimination.query\u001b[1;34m(self, variables, evidence, virtual_evidence, elimination_order, joint, show_progress)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# Step 3: Prune the network based on variables and evidence.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, BayesianNetwork):\n\u001b[1;32m--> 318\u001b[0m     model_reduced, evidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prune_bayesian_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     factors \u001b[38;5;241m=\u001b[39m model_reduced\u001b[38;5;241m.\u001b[39mcpds\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pgmpy\\inference\\base.py:153\u001b[0m, in \u001b[0;36mInference._prune_bayesian_model\u001b[1;34m(self, variables, evidence)\u001b[0m\n\u001b[0;32m    149\u001b[0m variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnodes()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(variables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(variables)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Step 1: Remove all the variables that are d-separated from `variables` when conditioned\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m#         on `evidence`\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m d_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_trail_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_latents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m d_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;241m*\u001b[39md_connected\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39munion(evidence\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    157\u001b[0m bn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msubgraph(d_connected)\n",
      "File \u001b[1;32mc:\\Users\\mique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pgmpy\\base\\DAG.py:719\u001b[0m, in \u001b[0;36mDAG.active_trail_nodes\u001b[1;34m(self, variables, observed, include_latents)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    718\u001b[0m     observed_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 719\u001b[0m ancestors_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ancestors_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobserved_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;66;03m# Direction of flow of information\u001b[39;00m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# up ->  from parent to child\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;66;03m# down -> from child to parent\u001b[39;00m\n\u001b[0;32m    725\u001b[0m active_trails \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\mique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pgmpy\\base\\DAG.py:781\u001b[0m, in \u001b[0;36mDAG._get_ancestors_of\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[1;32m--> 781\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in not in graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    783\u001b[0m ancestors_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    784\u001b[0m nodes_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(nodes)\n",
      "\u001b[1;31mValueError\u001b[0m: Node POSTMAT_1A not in not in graph"
     ]
    }
   ],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "'''\n",
    "AQUEST ÉS L'ESTUDI DE LA PROBABILITAT QUE ET VAIG FER INICIALMENT,\n",
    "PERÒ QUE FINALMENT NO VAM UTILITZAR, AIXÍ QUE HO PODRIES BORRAR\n",
    "\n",
    "NO FUNCIONA PERQUE DESPRÉS VAIG CANVIAR EL NOM D'ALGUNES VARIABLES\n",
    "'''\n",
    "\n",
    "infer = VariableElimination(VS_model)\n",
    "\n",
    "materialista = {\"POSTMAT_1A\": 1 , \"POSTMAT_1B\": 1, \"POSTMAT_2A\": 1, \"POSTMAT_2B\": 1}\n",
    "post_materialista = {\"POSTMAT_1A\": 2 , \"POSTMAT_1B\": 2, \"POSTMAT_2A\": 2, \"POSTMAT_2B\": 2}\n",
    "\n",
    "\n",
    "q = infer.query(variables=[\"ACTITUD_IMMIGRACIO\"], evidence=materialista)\n",
    "print('materialista:\\n', q)\n",
    "q = infer.query(variables=[\"ACTITUD_IMMIGRACIO\"], evidence=post_materialista)\n",
    "print('post_materialista:\\n', q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"ACTITUD_MEDIAMBIENT\"], evidence=materialista)\n",
    "print('materialista:\\n', q)\n",
    "q = infer.query(variables=[\"ACTITUD_MEDIAMBIENT\"], evidence=post_materialista)\n",
    "print('post_materialista: ', q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"CONFI_SOCIAL_WVS_1\"], evidence=materialista)\n",
    "print('materialista:\\n', q)\n",
    "q = infer.query(variables=[\"CONFI_SOCIAL_WVS_1\"], evidence=post_materialista)\n",
    "print('post_materialista:\\n', q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"DESIGUALTATS_GENERE\"], evidence=materialista)\n",
    "print('materialista:\\n', q)\n",
    "q = infer.query(variables=[\"DESIGUALTATS_GENERE\"], evidence=post_materialista)\n",
    "print('post_materialista:\\n', q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"IDEOL_0_10\"], evidence=materialista)\n",
    "print('materialista: ', q)\n",
    "q = infer.query(variables=[\"IDEOL_0_10\"], evidence=post_materialista)\n",
    "print('post_materialista:\\n', q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"LLENGUA_IDENTIFICACIO\"], evidence=materialista)\n",
    "print('materialista:\\n', q)\n",
    "q = infer.query(variables=[\"LLENGUA_IDENTIFICACIO\"], evidence=post_materialista)\n",
    "print('post_materialista:\\n', q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"IMP_RELIGIO\"], evidence=materialista)\n",
    "print('materialista:\\n', q)\n",
    "q = infer.query(variables=[\"IMP_RELIGIO\"], evidence=post_materialista)\n",
    "print('post_materialista:\\n', q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=materialista)\n",
    "print('materialista:\\n', q)\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=post_materialista)\n",
    "print('post_materialista:\\n', q)\n",
    "\n",
    "\n",
    "'''\n",
    "if x == 'No s’assembla a mi' or x=='No s’assembla gens a mi':\n",
    "    return 1\n",
    "elif x == 'S’assembla poc a mi' or x=='S’assembla una mica a mi':\n",
    "    return 2\n",
    "elif x == 'S’assembla a mi' or x=='S’assembla molt a mi':\n",
    "    return 3\n",
    "'''\n",
    "\n",
    "hedonisme_evidence = {\"VHB_J_HEDONISME1\": 3, \"VHB_U_HEDONISME2\": 3}\n",
    "autodireccio_evidence = {\"VHB_A_AUTODIRECCIO1\": 3, \"VHB_K_AUTODIRECCIO2\": 3}\n",
    "universalisme_evidence = {\"VHB_C_UNIVERSALISME1\": 3, \"VHB_H_UNIVERSALISME2\": 3, \"VHB_S_UNIVERSALISME3\": 3}\n",
    "poder_evidence = {\"VHB_B_PODER1\": 3, \"VHB_Q_PODER2\": 3}\n",
    "assoliment_evidence = {\"VHB_D_ASSOLIMENT1\": 3, \"VHB_M_ASSOLIMENT2\": 3}\n",
    "seguretat_evidence = {\"VHB_E_SEGURETAT1\": 3, \"VHB_N_SEGURETAT2\": 3}\n",
    "tradicio_evidence = {\"VHB_I_TRADICIO1\": 3, \"VHB_T_TRADICIO2\": 3}\n",
    "estimulant_evidence = {\"VHB_F_ESTIMULANT1\": 3, \"VHB_O_ESTIMULANT2\": 3}\n",
    "conformitat_evidence = {\"VHB_G_CONFORMITAT1\": 3, \"VHB_P_CONFORMITAT3\": 3}\n",
    "benevolencia_evidence= {\"VHB_L_BENEVOLENCIA1\": 3, \"VHB_R_BENEVOLENCIA2\": 3}\n",
    "\n",
    "hedonisme = [\"VHB_J_HEDONISME1\", \"VHB_U_HEDONISME2\"]\n",
    "autodireccio = [\"VHB_A_AUTODIRECCIO1\", \"VHB_K_AUTODIRECCIO2\"]\n",
    "universalisme = [\"VHB_C_UNIVERSALISME1\", \"VHB_H_UNIVERSALISME2\", \"VHB_S_UNIVERSALISME3\"]\n",
    "poder = [\"VHB_B_PODER1\", \"VHB_Q_PODER2\"]\n",
    "assoliment = [\"VHB_D_ASSOLIMENT1\", \"VHB_M_ASSOLIMENT2\"]\n",
    "seguretat = [\"VHB_E_SEGURETAT1\", \"VHB_N_SEGURETAT2\"]\n",
    "tradicio = [\"VHB_I_TRADICIO1\", \"VHB_T_TRADICIO2\"]\n",
    "estimulant = [\"VHB_F_ESTIMULANT1\", \"VHB_O_ESTIMULANT2\"]\n",
    "conformitat = [\"VHB_G_CONFORMITAT1\", \"VHB_P_CONFORMITAT3\"]\n",
    "benevolencia= [\"VHB_L_BENEVOLENCIA1\", \"VHB_R_BENEVOLENCIA2\"]\n",
    "\n",
    "q = infer.query(variables=tradicio, evidence={'IMP_RELIGIO': 'Molt important'})\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=universalisme, evidence={'MEDIAMBIENT_CREIXEMENT':\n",
    "    \"S'ha de prioritzar el medi ambient malgrat que alenteixi el creixement econòmic, però han de convervar-se i/o augmentar\"})\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=benevolencia, evidence={'IMP_AMICS': 'Molt important'})\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=seguretat, evidence={'ACTITUD_IMMIGRACIO': 1}) \n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"POSTMAT_2A\"], evidence=universalisme_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"IMP_LLEURE\"], evidence=hedonisme_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=benevolencia, evidence={'G': 'Femení'})\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=benevolencia, evidence={'G': 'Masculí'})\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"Ch\"], evidence=hedonisme_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=poder, evidence={'Ch': 2})\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"CONFI_POLICIA\"], evidence=conformitat_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=universalisme, evidence={'ACTITUD_IMMIGRACIO': 1})\n",
    "print(q)\n",
    "\n",
    "\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=hedonisme_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=autodireccio_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=universalisme_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=poder_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=assoliment_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=seguretat_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=tradicio_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=estimulant_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=conformitat_evidence)\n",
    "print(q)\n",
    "print('######################################################')\n",
    "q = infer.query(variables=[\"FELICITAT\"], evidence=benevolencia_evidence)\n",
    "print(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
